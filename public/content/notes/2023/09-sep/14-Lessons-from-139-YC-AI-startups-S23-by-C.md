-----------------------
articleLink: https://www.ignorance.ai/p/5-lessons-from-139-yc-ai-startups
articleTitle: Lessons from 139 YC AI startups (S23) - by Charlie Guo
createdOn: 2023-09-17T14:28:31.532Z
updatedOn: 2023-09-17T14:28:31.532Z
-----------------------

### (Their) Takeaways
- AI is (still) eating the world
  - AI Ops is a large, growing category
  - dev tools are making it easier to write code
  - Healthcare/biotech has a lot of room for automation
  - finance/payments: AI due dilligence/copilot for bankers
  - still a gap of on-premise, compliant LLMs for sensitive verticals
- copilots are king
  - last batch was "ChatGPT for X"
  - this batch is "copilot for X"
  - AI that lives in a sidebar and is only accessible via chat probably isn't the most useful form factor
- AI ops as a key sector
  - focus on training, fine-tuning, deploying, hosting, and post-processing LLMs
  - problems being solved:
    - Adding context to language models with as few as ten samples
    - Pausing and moving training runs in real-time
    - Managing training data ownership and permissions
    - Faster vector databases
    - Fine-tuning models with synthetic data
  - still much work needed to production-ize LLMs
    - questions on reliability, privacy, observability, usability and safety
- who owns the model? does it matter?
  - last batch: 
    - training their own model OR
    - fine-tuning GPT-3 OR
    - building a wrapper around OpenAI
  - this batch: most are using ChatGPT or fine-tuned LLAMA2
  - does it matter if it's "just" ChatGPT behind the scenes
  - once OpenAI delivers embedded fine-tuning, will startups ditch OpenAI and use their own models?
- AI isn't a silver bullet
  - you still need to build a defensible company
  - competition is fierce - common pitches:
    - solving support tickets
    - negotiating sales contracts
    - writing drafts of legal docs
    - no-code LLM workflows
    - On-prem LLM deployment
    - automating trust + safety moderation